{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlAQOxIzv8UgHkPGSD1HjK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theresaskruzna/riiid_knowledge_tracing/blob/main/03_Model_Building.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNbTad_dHiz_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building an RNN - LSTM model, binary classification"
      ],
      "metadata": {
        "id": "KSuWj6Jelvky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sequential_lstm_model(input_shape, hidden_units=128): # hidden_units=128 is default number that sets the number of neurons\n",
        "    model = Sequential() # creates sequential model = linear stack of layers\n",
        "    # input fits on X\n",
        "    model.add(Input(shape=X_train.shape[1:]))\n",
        "    # First LSTM(i.e.long short-term memory) layer with return sequences for stacking\n",
        "    model.add(LSTM(hidden_units, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(Dropout(0.2)) # prevent overfitting - randomly ignore 20% neurons during training\n",
        "    # use recurrent_dropout=0.2?\n",
        "\n",
        "    # Second LSTM layer without return sequences for final output\n",
        "    model.add(LSTM(hidden_units, return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(BatchNormalization()) # stabilize training and improve convergence\n",
        "\n",
        "        # Output layer with one neuron (for binary classification), sigmoid produces a probability between 0 and 1\n",
        "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01))) # L2 regularisor to prevent overfitting\n",
        "\n",
        "    model.compile( # configure learning process of the model\n",
        "        optimizer='adam', # specify opitimisation algorithm for training\n",
        "        loss='binary_crossentropy', # measure difference between predictions and actual values\n",
        "        metrics=['accuracy', tf.keras.metrics.AUC()] # set metrics to track during training and evaluation, AUC(area under the curve)\n",
        "    )\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "mv3cPf8fgF2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tweak model by changing number of hidden units and layers to optimise the architecture of the model"
      ],
      "metadata": {
        "id": "E5s2ebDxm9rp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Early stopping"
      ],
      "metadata": {
        "id": "KfYU5mhPnbdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    # monitor accuracy of the validation dataset\n",
        "    monitor=\"val_accuracy\",\n",
        "    # if it doesn't improve by at least 0.3%\n",
        "    min_delta=0.003,\n",
        "    # within the last 10 epochs\n",
        "    patience=10,\n",
        "    # turn it off and restore weights from the epoch with the highest accuracy on the validation set\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch = 50\n",
        ")"
      ],
      "metadata": {
        "id": "Q07sqqL_nUbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model checkpoint"
      ],
      "metadata": {
        "id": "6kZuCSjgosV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save = ModelCheckpoint(\n",
        "    # where to save model\n",
        "    filepath=\"best_model.keras\",\n",
        "    # monitor accuracy of the validation set\n",
        "    monitor=\"val_accuracy\",\n",
        "    # save only one file with the highest metrics value\n",
        "    save_best_only=True,\n",
        "    # save architecture and wights into one file\n",
        "    save_weights_only=False,\n",
        "    # after every epoch\n",
        "    save_freq=\"epoch\"\n",
        ")"
      ],
      "metadata": {
        "id": "WtBUpP7SorN_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}